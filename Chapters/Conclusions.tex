\documentclass[main-singleColumn.tex]{subfiles}
\begin{document}
%----------------------------------------------------------------------------------
%---------------------------------- INTRO -----------------------------------------
%----------------------------------------------------------------------------------
\section{Conclusions}

In this paper, a POD-PCE coupling for a field-measurement based Machine Learning is assessed, and takes place in an industrial context, for a complex physical phenomena involving non linear dynamics and various forcings. \\

First, the potential of POD for biased and missing data detection is demonstrated, through the investigation of the discontinuities that emerge in the temporal signals of the decomposition. Such a procedure is important because in practice, the data always need to be somehow \og filtered \fg{}, which could be time consuming. The POD allows a fast recognition of elements that react differentely from average. Further more, the POD investigation has shown that temporal signals can have different shapes (more or less regular) which can be related to the representation of different space or time scale physics. The study of correlations between the variables may be important for the interpretation of the dynamics, which highlights that keeping the mean information in the analyzed matrix is sometimes worthy. In the end, the missing data were delt with either by a selection of quality data only which decreases the size of the studied set, or by restraining the spatial analysis. Here, it has been shown that bad quality measurements may as well have valuable information in the spaces where they are well defined. \\

Second, the PCE was used to learn the temporal POD modes as 1D data. We showed the importance of the polynomial basis and therefore of the marginals choice for the learning phase. In this comparison process, we showed that choosing Uniform distributions associated with Legendre family is not always a good choice, even though it is widely used when no information about the inputs is available. Also, the number of involved inputs can alter the learning. In fact, when using LARS, the presence of numerous variables could misslead the algorithm is selecting useless variables that seem to decrease the training error but that make the prediction errors greater. This is somehow an overfitting phenomena. In the end, a good combined polynomial basis and dimension choice could significantly improve the convergence speed, the centering of the residuals and the mean training and prediction errors. \\

Third, the proposed sensitivity analysis using the PCE coefficients allowed to show that the last state information is often the most influencing input. A robustness test was conducted by varying the training set, and the observation is stable. For the modes of small ranks associated to the biggest variances (modes 1 to 4 in our example), the waves height seems to be always influencial whatever the chosen data set. For the modes of higher ranks however, the only selected variable by LARS is the last state information. \\

Finally, the previous conclusions on the sensitivity of PCE models to the inputs encouraged a comparison between a POD-PCE prediction using the 15 first modes, and a \og corrected \fg{} POD-PCE prediction, where the modes of higher ranks are simply approximated by linearization around their previous values. This procedure allows to get rid of the noisy polynomial terms that may be added in the PCE approximation of the modes of higher ranks. These noisy polynomial terms are not only associated to small contribution weights but also happen to be polynomials of higher degrees. This means that if any uncertainty occurs in the inputs, it propagates even faster and higher toward the output space. \\

The corrected prediction has shown good characteristics. Mean information (e.g. Silting Rate) are generally well approximated.  A profile by profile investigations also shows that the POD-PCE coupling is promising as the spatial ditribution of the silting is well detected and the amplitudes well approached. \\

Some limitations should be highlighted and could represented good perspectives for the improvement of the process. First, the small data was a clear handicap in our problem. It would be interesting to test the methodology on an enriched data set in order to assess the real potential of the POD-PCE Machine Learning. Further more, the input variables were chosen with an apriori, not only when calculating statistical estimators over the evolution period, but also when choosing the dimension of the problem. This can clearly be done in a more robust and objective way. Last, due to the lack of the data, the input distributions are certainly poorly approximated and the dependencies are not taken account of. A good perspective would be a hybrid measurement-based and numerical-based data learning, which could be used to enrich the data set, not only by increasing its size (emulated realistic scenarios) but also by adding input parameters that are not measured (for e.g. via a data assimilation process). 


%---------------------------------------------------------------------------

\end{document}
